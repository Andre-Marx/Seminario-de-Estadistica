{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### André Marx Puente Arévalo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tarea 1 Primera Parte\n",
    "### Seminario de Estadística \n",
    "Debera entregar su tarea en este notebook (prohibido usar R).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Respuestas:\n",
    "\n",
    "1.- Ajuste un modelo de regresión multiple para los datos de crimen, explique. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerias que vamos a usar\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy  as np  \n",
    "import matplotlib.pyplot as plt \n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijamos una semilla\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>M</th>\n",
       "      <th>So</th>\n",
       "      <th>Ed</th>\n",
       "      <th>Po1</th>\n",
       "      <th>LF</th>\n",
       "      <th>M.F</th>\n",
       "      <th>Pop</th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79.1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>58</td>\n",
       "      <td>510</td>\n",
       "      <td>950</td>\n",
       "      <td>33</td>\n",
       "      <td>108</td>\n",
       "      <td>41</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163.5</td>\n",
       "      <td>143</td>\n",
       "      <td>0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>103</td>\n",
       "      <td>583</td>\n",
       "      <td>1012</td>\n",
       "      <td>13</td>\n",
       "      <td>96</td>\n",
       "      <td>36</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57.8</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>45</td>\n",
       "      <td>533</td>\n",
       "      <td>969</td>\n",
       "      <td>18</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196.9</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>149</td>\n",
       "      <td>577</td>\n",
       "      <td>994</td>\n",
       "      <td>157</td>\n",
       "      <td>102</td>\n",
       "      <td>39</td>\n",
       "      <td>673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123.4</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>109</td>\n",
       "      <td>591</td>\n",
       "      <td>985</td>\n",
       "      <td>18</td>\n",
       "      <td>91</td>\n",
       "      <td>20</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y    M  So    Ed  Po1   LF   M.F  Pop   U1  U2  GDP\n",
       "0   79.1  151   1   9.1   58  510   950   33  108  41  394\n",
       "1  163.5  143   0  11.3  103  583  1012   13   96  36  557\n",
       "2   57.8  142   1   8.9   45  533   969   18   94  33  318\n",
       "3  196.9  136   0  12.1  149  577   994  157  102  39  673\n",
       "4  123.4  141   0  12.1  109  591   985   18   91  20  578"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leemos los datos y los mostramos\n",
    "datos_crime = pd.read_csv(\"crime.csv\")\n",
    "datos_crime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defino la Matriz de respuesta\n",
    "Y = datos_crime.iloc[ :, 0 ]\n",
    "\n",
    "# Defino la matriz de Covariables\n",
    "X = datos_crime.iloc[ : , 1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Creamos el modelo sin intercepto\n",
    "# Nota: Estoy ajustando con el modelo de mínimos cuadrados ordinarios (OLS)\n",
    "modelo0 = sm.OLS(Y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros:  M      0.614559\n",
      "So     9.643184\n",
      "Ed     8.679113\n",
      "Po1    1.236030\n",
      "LF     0.194131\n",
      "M.F   -0.264325\n",
      "Pop   -0.129785\n",
      "U1    -0.086498\n",
      "U2     1.115094\n",
      "GDP   -0.130193\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculamos los valores de las Betas \n",
    "parametros0 = sm.OLS(Y, X).fit().params\n",
    "print(\"Parámetros: \", parametros0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.936\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.918\n",
      "Method:                 Least Squares   F-statistic:                              53.86\n",
      "Date:                Fri, 18 Oct 2019   Prob (F-statistic):                    5.58e-19\n",
      "Time:                        20:30:43   Log-Likelihood:                         -217.81\n",
      "No. Observations:                  47   AIC:                                      455.6\n",
      "Df Residuals:                      37   BIC:                                      474.1\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "M              0.6146      0.491      1.251      0.219      -0.381       1.610\n",
      "So             9.6432     15.134      0.637      0.528     -21.022      40.308\n",
      "Ed             8.6791      7.730      1.123      0.269      -6.984      24.342\n",
      "Po1            1.2360      0.271      4.557      0.000       0.686       1.786\n",
      "LF             0.1941      0.173      1.123      0.269      -0.156       0.544\n",
      "M.F           -0.2643      0.175     -1.507      0.140      -0.620       0.091\n",
      "Pop           -0.1298      0.141     -0.918      0.365      -0.416       0.157\n",
      "U1            -0.0865      0.515     -0.168      0.867      -1.129       0.956\n",
      "U2             1.1151      1.034      1.079      0.288      -0.979       3.210\n",
      "GDP           -0.1302      0.103     -1.265      0.214      -0.339       0.078\n",
      "==============================================================================\n",
      "Omnibus:                        0.534   Durbin-Watson:                   2.152\n",
      "Prob(Omnibus):                  0.766   Jarque-Bera (JB):                0.080\n",
      "Skew:                           0.024   Prob(JB):                        0.961\n",
      "Kurtosis:                       3.196   Cond. No.                     4.68e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.68e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Vemos el resumen del modelo\n",
    "print(modelo0.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, calculo el modelo con intercepto\n",
    "modelo1 = sm.OLS(Y, sm.add_constant(X)).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros:  const   -589.399852\n",
      "M          1.040580\n",
      "So        11.294643\n",
      "Ed        11.779424\n",
      "Po1        0.963636\n",
      "LF         0.106043\n",
      "M.F        0.303531\n",
      "Pop        0.090416\n",
      "U1        -0.681791\n",
      "U2         2.150278\n",
      "GDP       -0.083087\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculamos los valores de las Betas \n",
    "parametros = sm.OLS(Y, sm.add_constant(X)).fit().params\n",
    "print(\"Parámetros: \", parametros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.684\n",
      "Model:                            OLS   Adj. R-squared:                  0.597\n",
      "Method:                 Least Squares   F-statistic:                     7.809\n",
      "Date:                Fri, 18 Oct 2019   Prob (F-statistic):           1.70e-06\n",
      "Time:                        20:30:43   Log-Likelihood:                -210.87\n",
      "No. Observations:                  47   AIC:                             443.7\n",
      "Df Residuals:                      36   BIC:                             464.1\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -589.3999    167.591     -3.517      0.001    -929.289    -249.510\n",
      "M              1.0406      0.446      2.331      0.025       0.135       1.946\n",
      "So            11.2946     13.245      0.853      0.399     -15.568      38.157\n",
      "Ed            11.7794      6.818      1.728      0.093      -2.048      25.607\n",
      "Po1            0.9636      0.250      3.862      0.000       0.458       1.470\n",
      "LF             0.1060      0.153      0.692      0.493      -0.205       0.417\n",
      "M.F            0.3035      0.223      1.363      0.181      -0.148       0.755\n",
      "Pop            0.0904      0.139      0.652      0.518      -0.191       0.372\n",
      "U1            -0.6818      0.481     -1.418      0.165      -1.657       0.293\n",
      "U2             2.1503      0.951      2.262      0.030       0.222       4.079\n",
      "GDP           -0.0831      0.091     -0.913      0.367      -0.268       0.101\n",
      "==============================================================================\n",
      "Omnibus:                        1.885   Durbin-Watson:                   1.776\n",
      "Prob(Omnibus):                  0.390   Jarque-Bera (JB):                1.249\n",
      "Skew:                           0.392   Prob(JB):                        0.535\n",
      "Kurtosis:                       3.154   Cond. No.                     5.92e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.92e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Vemos el resumen del modelo\n",
    "print(modelo1.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explicación:\n",
    "Dado que el modelo1, es decir el que tiene intercepto, tiene menor AIC y menor BIC que el modelo0 (el que no tiene intercepto), es el mejor modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ¿Qué observaba acerca de los coeficientes obtenidos?\n",
    "\n",
    "Observo que aún se puede mejorar el modelo, debido a que observando los p-values, notamos que hay coeficientes que no son significantes para el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ¿Cuantos posibles submodelos puede ajustar? \n",
    "\n",
    "Puedo ajustar\n",
    "$2^{11} = 2048 $ modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Considerando una sola covariable. ¿ Cuál es el mejor submodelo sin considerar la propiedad de consistencia del estimador que minimiza la función de Riesgo $A(f,\\hat{f})$? Grafique el modelo regresión con los datos experimentales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Lo que haré a continuación es realizar submodelos de una sola variable y como sabemos, el AIC es un estimador que no es consistente, por lo que me quedaré con el modelo que lo minimice más."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.918\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.916\n",
      "Method:                 Least Squares   F-statistic:                              513.3\n",
      "Date:                Fri, 18 Oct 2019   Prob (F-statistic):                    1.36e-26\n",
      "Time:                        20:30:43   Log-Likelihood:                         -223.61\n",
      "No. Observations:                  47   AIC:                                      449.2\n",
      "Df Residuals:                      46   BIC:                                      451.1\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Po1            1.0466      0.046     22.656      0.000       0.954       1.140\n",
      "==============================================================================\n",
      "Omnibus:                        4.001   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.135   Jarque-Bera (JB):                3.263\n",
      "Skew:                          -0.642   Prob(JB):                        0.196\n",
      "Kurtosis:                       3.129   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--------------------------------------------------------------------------------------------\n",
      "El mejor submodelo es el que tiene la covariable número 4 con un AIC de 449.21122570700936\n"
     ]
    }
   ],
   "source": [
    "Y = datos_crime.iloc[ :, 0 ]\n",
    "AIC = 10000\n",
    "k = 0\n",
    "AIC_I = 1000\n",
    "\n",
    "# El siguiente for lo que hace es crear los submodelos\n",
    "for i in range(1, 11):\n",
    "    # Matriz de covariables\n",
    "    X_AIC = datos_crime.iloc[:, i ]\n",
    "    \n",
    "    # Defino el modelo\n",
    "    modelo_AIC = sm.OLS(Y, X_AIC).fit()\n",
    "    \n",
    "    # Defino modelo con intercepto\n",
    "    modelo_AIC_I = sm.OLS(Y, sm.add_constant(X_AIC)).fit()\n",
    "    \n",
    "    #Creamos un diccionario con el AIC del modelo con intercepto y el AIC del modelo sin intercepto\n",
    "    AIC_sup = dict(one = modelo_AIC.aic, two = modelo_AIC_I.aic) \n",
    "    modeloAIC =  dict(one = modelo_AIC, two = modelo_AIC_I) #Guardamos los dos modelos (con y sin intercepto)\n",
    "    \n",
    "    #Encontramos el mínimo de los AIC's del diccionario para saber si es mejor el que tiene intercepto o no\n",
    "    AIC_min_nombre = min(AIC_sup, key=AIC_sup.get) #AIC_min_nombre guarda el nombre de la variable que contiene el AIC de los modelo\n",
    "    AIC_min_valor = min(AIC_sup.values())          #AIC_min_valor guarda mínimo valor entre los AIC's      \n",
    "    \n",
    "    # Este if compara el AIC mínimo entre los modelos con intercepto y sin intercepto de cada covariable con el AIC mínimo\n",
    "    # de los modelos anteriores que se han probado, inicializamos la variable AIC con un número muy grande para que entre la \n",
    "    # covariable al if.\n",
    "    \n",
    "    \n",
    "    if AIC_min_valor < AIC:\n",
    "        modelo = modeloAIC[AIC_min_nombre]\n",
    "        AIC = AIC_min_valor\n",
    "        # Esta variable es para saber que modelo fue el de menor AIC\n",
    "        k = i\n",
    "            \n",
    "print(modelo.summary())    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(f\"El mejor submodelo es el que tiene la covariable número {k} con un AIC de {AIC}\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los parametros a numeros\n",
    "beta = float(modelo.params)\n",
    "\n",
    "# Matriz con la mejor covariable\n",
    "X_AIC = datos_crime.iloc[:, k ]\n",
    "\n",
    "# Defino la matriz de respuesta ajuastada\n",
    "Y_AIC = beta * X_AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Realizamos un grafico de dispersión ( Scatter-Plot )\n",
    "plt.figure( figsize=(16,4) )                           \n",
    "plt.title(\"Scatter Plot\")                              \n",
    "plt.scatter( X_AIC, Y, label = \"Etiqueta de la serie\")    \n",
    "plt.plot( X_AIC, Y_AIC, color=\"red\")  \n",
    "plt.xlabel(\"Eje X\")                                   \n",
    "plt.ylabel(\"Eje Y\")                                    \n",
    "plt.grid()                                             \n",
    "plt.legend()                                           \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Use el criterio de información Bayesiana para seleccionar el mejor submodelo.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que haremos será exáctamente lo mismo que en el inciso anterior, solo que en este caso,nos quedaremos con el submodelo que minimice más el BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.918\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.916\n",
      "Method:                 Least Squares   F-statistic:                              513.3\n",
      "Date:                Fri, 18 Oct 2019   Prob (F-statistic):                    1.36e-26\n",
      "Time:                        20:30:44   Log-Likelihood:                         -223.61\n",
      "No. Observations:                  47   AIC:                                      449.2\n",
      "Df Residuals:                      46   BIC:                                      451.1\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Po1            1.0466      0.046     22.656      0.000       0.954       1.140\n",
      "==============================================================================\n",
      "Omnibus:                        4.001   Durbin-Watson:                   2.010\n",
      "Prob(Omnibus):                  0.135   Jarque-Bera (JB):                3.263\n",
      "Skew:                          -0.642   Prob(JB):                        0.196\n",
      "Kurtosis:                       3.129   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "--------------------------------------------------------------------------------------------\n",
      "El mejor submodelo es el que tiene la covariable número 4 con un BIC de 451.0613733087194\n"
     ]
    }
   ],
   "source": [
    "Y = datos_crime.iloc[ :, 0 ]\n",
    "BIC = 10000\n",
    "k = 0\n",
    "BIC_I = 1000\n",
    "\n",
    "# El siguiente for lo que hace es crear los submodelos\n",
    "for i in range(1, 11):\n",
    "    # Matriz de covariables\n",
    "    X_BIC = datos_crime.iloc[:, i ]\n",
    "    \n",
    "    # Defino el modelo\n",
    "    modelo_BIC = sm.OLS(Y, X_BIC).fit()\n",
    "    \n",
    "    # Defino modelo con intercepto\n",
    "    modelo_BIC_I = sm.OLS(Y, sm.add_constant(X_BIC)).fit()\n",
    "    \n",
    "    #Creamos un diccionario con el BIC del modelo con intercepto y el BIC del modelo sin intercepto\n",
    "    BIC_sup = dict(one = modelo_BIC.bic, two = modelo_BIC_I.bic) \n",
    "    \n",
    "    #Guardamos los dos modelos (con y sin intercepto)\n",
    "    modeloBIC =  dict(one = modelo_BIC, two = modelo_BIC_I) \n",
    "    \n",
    "    #Encontramos el mínimo de los BIC's del diccionario para saber si es mejor el que tiene intercepto o no\n",
    "    BIC_min_nombre = min(BIC_sup, key=BIC_sup.get) #BIC_min_nombre guarda el nombre de la variable que contiene el BIC de los modelo\n",
    "    BIC_min_valor = min(BIC_sup.values())          #BIC_min_valor guarda mínimo valor entre los BIC's      \n",
    "    \n",
    "    \n",
    "    #Este if compara el BIC mínimo entre los modelos con intercepto y sin intercepto de cada covariable con el BIC mínimo\n",
    "    #de los modelos anteriores que se han probado, inicializamos la variable BIC con un número muy grande para que entre la \n",
    "    #covariable al if.\n",
    "    \n",
    "    \n",
    "    if BIC_min_valor < BIC:\n",
    "        modelo = modeloBIC[BIC_min_nombre]\n",
    "        BIC = BIC_min_valor\n",
    "        \n",
    "        # Esta variable es para saber que modelo fue el de menor BIC\n",
    "        k = i\n",
    "            \n",
    "print(modelo.summary())    \n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "print(f\"El mejor submodelo es el que tiene la covariable número {k} con un BIC de {BIC}\" )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Ahora considerando todas las covariables reduzca al mejor submodelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procederemos haciendo el método $\\textbf{Backward}$, el cual consiste en modelar con todas las variables e ir quitando la \"menos significativa\", es decir, la que tenga el p-value más alto y que sea mayor al nivel de significancia (0.05), esto lo haremos hasta que todas nuestras covariables que queden en el modelo sean significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.600\n",
      "Model:                            OLS   Adj. R-squared:                  0.573\n",
      "Method:                 Least Squares   F-statistic:                     21.54\n",
      "Date:                Fri, 18 Oct 2019   Prob (F-statistic):           1.14e-08\n",
      "Time:                        20:30:44   Log-Likelihood:                -216.42\n",
      "No. Observations:                  47   AIC:                             440.8\n",
      "Df Residuals:                      43   BIC:                             448.2\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const       -405.2784    136.436     -2.970      0.005    -680.427    -130.130\n",
      "M              1.0773      0.344      3.133      0.003       0.384       1.771\n",
      "Po1            1.1167      0.145      7.677      0.000       0.823       1.410\n",
      "M.F            0.2559      0.127      2.021      0.049       0.001       0.511\n",
      "==============================================================================\n",
      "Omnibus:                        0.018   Durbin-Watson:                   1.709\n",
      "Prob(Omnibus):                  0.991   Jarque-Bera (JB):                0.127\n",
      "Skew:                           0.043   Prob(JB):                        0.939\n",
      "Kurtosis:                       2.760   Cond. No.                     3.69e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 3.69e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Haremos el while para que nos vaya haciendo los modelos y quite el de mayor p-value y\n",
    "# el que sea mas grane al nivel de significancia\n",
    "\n",
    "X = datos_crime.iloc[ : , 1: ]\n",
    "estpvalue = 1\n",
    "Y = datos_crime.iloc[ :, 0 ]\n",
    "\n",
    "while estpvalue > 0.05:  \n",
    "    \n",
    "    ##Ajuste del modelo\n",
    "    X = sm.add_constant(X) \n",
    "    est = sm.OLS(Y, X).fit() \n",
    "    \n",
    "    ##encuentra la covariable con el pvalue más grande\n",
    "    estpvalue1 = est.pvalues.argmax()\n",
    "    \n",
    "    ##quita la covariable \n",
    "    X = X.drop(columns = estpvalue1)\n",
    "    \n",
    "    ##actualiza el valor del pvalue más grande\n",
    "    estpvalue = est.pvalues.max() \n",
    "    \n",
    "print(est.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este último modelo es el mejor, ya que, es el que más ha minimizado el AIC y el BIC y los p-values de las covariables son menores al nivel de significancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Asuma un modelo de regresión lineal con errores normales y $\\sigma$ conocida. Mostrar que el modelo con AIC mas grande es el modelo con $C_p$ Mallows más pequeño."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Con los datos del creditos, obtenga el performance del modelo. Obtenga el error empirico, con una muestra de entrenamiento training_sample=60,70,80,9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las paqueterias que vamos a ocupar\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folio</th>\n",
       "      <th>Incumplimiento</th>\n",
       "      <th>Estudiante</th>\n",
       "      <th>Saldo</th>\n",
       "      <th>Ingreso</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Folio Incumplimiento Estudiante        Saldo       Ingreso\n",
       "0      1             No         No   729.526495  44361.625074\n",
       "1      2             No        Yes   817.180407  12106.134700\n",
       "2      3             No         No  1073.549164  31767.138947\n",
       "3      4             No         No   529.250605  35704.493935\n",
       "4      5             No         No   785.655883  38463.495879"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos los datos\n",
    "data = pd.read_csv(\"incumplimiento.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, lo que haremos será convertir las variables categóricas (\"Estudiante\" e \"Incumplimiento\") en variables numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folio</th>\n",
       "      <th>Incumplimiento</th>\n",
       "      <th>Estudiante</th>\n",
       "      <th>Saldo</th>\n",
       "      <th>Ingreso</th>\n",
       "      <th>Estudiante_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Folio Incumplimiento Estudiante        Saldo       Ingreso  Estudiante_enc\n",
       "0      1             No         No   729.526495  44361.625074               0\n",
       "1      2             No        Yes   817.180407  12106.134700               1\n",
       "2      3             No         No  1073.549164  31767.138947               0\n",
       "3      4             No         No   529.250605  35704.493935               0\n",
       "4      5             No         No   785.655883  38463.495879               0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Los 0 -> No estudiante y los 1 -> Si son estudiantes\n",
    "data['Estudiante_enc'] = LabelEncoder().fit_transform(data['Estudiante'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Folio</th>\n",
       "      <th>Incumplimiento</th>\n",
       "      <th>Estudiante</th>\n",
       "      <th>Saldo</th>\n",
       "      <th>Ingreso</th>\n",
       "      <th>Estudiante_enc</th>\n",
       "      <th>Incumplimiento_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>711.555020</td>\n",
       "      <td>52992.378914</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>757.962918</td>\n",
       "      <td>19660.721768</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>845.411989</td>\n",
       "      <td>58636.156984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1569.009053</td>\n",
       "      <td>36669.112365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>200.922183</td>\n",
       "      <td>16862.952321</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Folio Incumplimiento Estudiante        Saldo       Ingreso  \\\n",
       "9995   9996             No         No   711.555020  52992.378914   \n",
       "9996   9997             No         No   757.962918  19660.721768   \n",
       "9997   9998             No         No   845.411989  58636.156984   \n",
       "9998   9999             No         No  1569.009053  36669.112365   \n",
       "9999  10000             No        Yes   200.922183  16862.952321   \n",
       "\n",
       "      Estudiante_enc  Incumplimiento_enc  \n",
       "9995               0                   0  \n",
       "9996               0                   0  \n",
       "9997               0                   0  \n",
       "9998               0                   0  \n",
       "9999               1                   0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 -> No cumple y 0 -> Si cumple\n",
    "data['Incumplimiento_enc'] = LabelEncoder().fit_transform(data['Incumplimiento'])\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la matriz de variables explicativas (covariables)\n",
    "x = data.iloc[:, 3:6]\n",
    "\n",
    "# Definimos la matriz de respuesta\n",
    "y = data.loc[:, \"Incumplimiento_enc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Saldo</th>\n",
       "      <th>Ingreso</th>\n",
       "      <th>Estudiante_enc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Saldo       Ingreso  Estudiante_enc\n",
       "0   729.526495  44361.625074               0\n",
       "1   817.180407  12106.134700               1\n",
       "2  1073.549164  31767.138947               0\n",
       "3   529.250605  35704.493935               0\n",
       "4   785.655883  38463.495879               0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las betas son: [ 5.73384566e-03  2.94312132e-06 -6.48630532e-01]\n",
      "Intercepta al eje en: [-10.86103156]\n"
     ]
    }
   ],
   "source": [
    "# Ajustamos un modelo de regresion logistica\n",
    "model = LogisticRegression(C = 100, solver = 'newton-cg', max_iter = 10000).fit(x, y) # c es parametro de penalizacion (mientras mayor mejor)\n",
    "print(f\"Las betas son: {model.coef_[0]}\")\n",
    "print(f\"Intercepta al eje en: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuacion, definiremos los porcentajes que serán para la parte de training (entrenamiento) y test (predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos un vector que contenga los porcentajes para el test_sample\n",
    "porcentajes = np.array([1-.6, 1-.7, 1-.8, 1-.9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que:\n",
    "<center> Accuracy score = 1 - Tasa de error empírico </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El accuracy score del modelo es: 0.9748773325558148\n",
      "El error empírico del modelo es: 0.02512266744418523\n"
     ]
    }
   ],
   "source": [
    "# El siguiente for lo que hace es calcular el perfomance y el error empirico del modelo\n",
    "\n",
    "i = 0\n",
    "\n",
    "# Esta lista guardara los accuracy score de los modelos\n",
    "accuracy=[]\n",
    "\n",
    "for i in porcentajes:\n",
    "    # i% de la muestra lo guarda para el test, lo demas lo guarda en el trainning\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = i)\n",
    "    \n",
    "    # Modelo de entrenamiento construido con datos de entrenamiento (1-i)% de la muestra\n",
    "    model = LogisticRegression(C = 100, solver = 'newton-cg', max_iter = 10000).fit(x_train, y_train)\n",
    "    \n",
    "    # Calculo cual va a ser la prediccion del modelo\n",
    "    yp0 = model.predict(x_test)\n",
    "    \n",
    "    # En esta parte rellenamos el accuracy con el respectivo accuracy score de cada\n",
    "    # training sample\n",
    "  \n",
    "    accuracy.append(accuracy_score(y_test, yp0, normalize = True))\n",
    "\n",
    "print(f\"El accuracy score del modelo es: {np.mean(accuracy)}\")\n",
    "print(f\"El error empírico del modelo es: {1-np.mean(accuracy)}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
